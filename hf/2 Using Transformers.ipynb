{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc8a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from transformers import pipeline\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc11dc",
   "metadata": {},
   "source": [
    "Personal playground containing recreations of examples from the Hugging Face tutorial course.\n",
    "\n",
    "### Table of Contents\n",
    "* [`pipeline` demos](#pipeline-demos)\n",
    "* [`pipeline` under the hood](#pipeline-breakdown)\n",
    "* [`Model` intro](#model-intro)\n",
    "* [`Tokenizer` intro](#tokenizer-intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49c7b9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SequenceClassifierOutput</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logits</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5607</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6123</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.6183</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.9137</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hidden_states</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequenceClassifierOutput\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mloss\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mlogits\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.5607\u001b[0m,  \u001b[1;36m1.6123\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-3.6183\u001b[0m,  \u001b[1;36m3.9137\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mhidden_states\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mattentions\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### TLDR Code ####\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
    "\n",
    "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output = model(**tokens)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51a9acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9507</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0493</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7297</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2703</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9507\u001b[0m, \u001b[1;36m0.0493\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.7297\u001b[0m, \u001b[1;36m0.2703\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'POSITIVE'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[32m'NEGATIVE'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'POSITIVE'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = F.softmax(outputs.logits, dim=-1)\n",
    "print(predictions) # Convert logits to probabilities\n",
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336009f",
   "metadata": {},
   "source": [
    "### Quick Access to Task-specific Models with `pipeline`<a class=\"anchor\" id=\"pipeline-demos\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5aea929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d70a3df8eab459d814525dcd8cc5392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb2a33d5bd1489285bb75973f05b19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d9c5533e0344a39c887f358f108c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790d12598274b3ca600f0cfe058ee30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9516071081161499}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic usage of pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1200747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9516071081161499},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass multiple texts to object\n",
    "classifier([\n",
    "  \"I've been waiting for a HuggingFace course my whole life\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31166c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5aa3ab570c44096acd2c7d2a5cb7ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063f5c75903744a1a8f5821964ae72b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bb8b86573f44bc80d1f6d4b9b2b499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74d50ae9df0415687ff570aa116661b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdacd2a2f234873bc0e302dd5441474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfca712901404658a3fa84d070bc04de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445985913276672, 0.11197447776794434, 0.04342697560787201]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f592e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977b0bec1c534882851bf77eb9bef57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d17e88fd9404c77a2e812350cc08857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b6da2d4df4662ab6cdbe33a982600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aae8a6291fe425cb50e570f2a288957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d4974e558340c983f0e22d2a22eaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/n/fs/nlp-jy1682/miniconda3/envs/learn/lib/python3.8/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to build a complete Java application using J2EE 8 and Java EE 8, both of which include cross platform execution frameworks. We will cover both Java EE and Java 8 to implement code generation and a series'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Generation\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad6b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39232589741148d6884f68f720d1187f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b3701fbd4f4f12b95c9754fc6fc090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecc7a36d0404aab90263fb10abfc49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150e785ea85c4ad6bc721bbd746ee42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493c26ff08c74e228036cfe135e01883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to make a good bet. It gives you the information that you need to follow the course. If you'},\n",
       " {'generated_text': 'In this course, we will teach you how to be a good programmer. With this course, we will make you more able to learn how to use'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Generation with specific model specified (specify as pipeline(<task>, model=<model>))\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e384718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eaaf022ea54175a1af8f7ca224fe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22829af3b02d4e3090829f5add1048d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d1183c1356411babede0cff9b503fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdf23f9a3124d539b8fd4609d1c0bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb72293dbf64bb59343ce2e2840b00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.196197971701622,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052729904651642,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill-mask pipeline will predict missing words in a sentence\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f28e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8d7afa6aff4100a9076bcc5a96be48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243ae3c2e5fb49a599f9fc70efa7b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631879ff85f64b9291b7b5545621b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f09c577a2074e928b6ad6f867f84394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/nlp-jy1682/miniconda3/envs/learn/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:159: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.97960186,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NER (Named Entity Recognition) pipeline identifies entities such as persons, orgs, locations\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b84f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d674c3fb2e1a46b3952ef6c16bcb3554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca98fb8540144a583cc06706c48abe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cfbe005bc5437dab58797374e9fdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d24299da794482aa7d12cf9337871ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29be609706a49cab1a1b68cc2b244f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949759125709534, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QA pipeline extracts answers to a question from a given context\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7207751",
   "metadata": {},
   "source": [
    "### Breaking Down Pipeline<a class=\"anchor\" id=\"pipeline-breakdown\"></a>\n",
    "The `pipeline` function is an abstraction of three separate steps:\n",
    "* Preprocessing with a Tokenizer (Raw Text => Input IDs)\n",
    "* Process Inputs with a Model (Input IDs => Logits)\n",
    "* Postprocessing (Logist => Predictions)\n",
    "\n",
    "We demonstrate this with the following example of the sentiment analysis task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657d5db",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a34e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdb7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84950bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2310</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2042</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12172</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2607</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2878</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2166</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5223</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2061</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2172</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "             <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'input_ids'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,  \u001b[1;36m1045\u001b[0m,  \u001b[1;36m1005\u001b[0m,  \u001b[1;36m2310\u001b[0m,  \u001b[1;36m2042\u001b[0m,  \u001b[1;36m3403\u001b[0m,  \u001b[1;36m2005\u001b[0m,  \u001b[1;36m1037\u001b[0m, \u001b[1;36m17662\u001b[0m, \u001b[1;36m12172\u001b[0m,\n",
       "          \u001b[1;36m2607\u001b[0m,  \u001b[1;36m2026\u001b[0m,  \u001b[1;36m2878\u001b[0m,  \u001b[1;36m2166\u001b[0m,  \u001b[1;36m1012\u001b[0m,   \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,  \u001b[1;36m1045\u001b[0m,  \u001b[1;36m5223\u001b[0m,  \u001b[1;36m2023\u001b[0m,  \u001b[1;36m2061\u001b[0m,  \u001b[1;36m2172\u001b[0m,   \u001b[1;36m999\u001b[0m,   \u001b[1;36m102\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,\n",
       "             \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'attention_mask'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_inputs = [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Two outputs\n",
    "# * input_ids: two rows of integers that are unique identifiers of tokens in each sentence\n",
    "# * attention_mask: \n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d17ed6",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9ba019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# This archiecture is base Transformer module: inputs => hidden states\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model = AutoModel.from_pretrained(checkpoint) # Outputs hidden states (a.k.a. features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6bb08a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per input, we receive a high dimensional vector representation of the input\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Size will be: # (batch size, sequence length, hidden size)\n",
    "# - Batch size: # of sequences processed at a time (2)\n",
    "# - Sequence length: Length of numerical repr. of sequence (16)\n",
    "# - Hidden size: Vector dimension of each model input (768)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e13860dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF also has models that include task-specific heads (output logits, not hidden states)\n",
    "# List: ForCausalLM, ForMaskedLM, ForMUltipleChoice, ForQuestionAnswering,\n",
    "#   ForSequenceClassification, ForTokenClassification\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "331dd269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SequenceClassifierOutput</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logits</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5607</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6123</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.1692</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.3464</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hidden_states</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequenceClassifierOutput\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mloss\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mlogits\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.5607\u001b[0m,  \u001b[1;36m1.6123\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m4.1692\u001b[0m, \u001b[1;36m-3.3464\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mhidden_states\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mattentions\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f10ee",
   "metadata": {},
   "source": [
    "#### Post Processing\n",
    "* Model predicted logits (raw, unnormalized scores outputted by model's last layer)\n",
    "* To convert to a probability, they must go through a `softmax` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eed23a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0195e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.5981e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.9946e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4418e-04</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4.0195e-02\u001b[0m, \u001b[1;36m9.5981e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m9.9946e-01\u001b[0m, \u001b[1;36m5.4418e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = F.softmax(outputs.logits, dim=-1)\n",
    "print(predictions) # Convert logits to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37da9fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the indices to the corresponding label\n",
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da91094",
   "metadata": {},
   "source": [
    "### Intro to `Model`<a class=\"anchor\" id=\"model-intro\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08dff637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Build the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Build model from config\n",
    "model = BertModel(config)\n",
    "\n",
    "# The above will created a model initialized with random values (untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "500d4643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BertConfig <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attention_probs_dropout_prob\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"classifier_dropout\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_act\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_dropout_prob\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"intermediate_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"layer_norm_eps\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"max_position_embeddings\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"bert\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"num_attention_heads\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"num_hidden_layers\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"pad_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"position_embedding_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"absolute\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.25.1\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"type_vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"use_cache\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "BertConfig \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"attention_probs_dropout_prob\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"classifier_dropout\"\u001b[0m: null,\n",
       "  \u001b[32m\"hidden_act\"\u001b[0m: \u001b[32m\"gelu\"\u001b[0m,\n",
       "  \u001b[32m\"hidden_dropout_prob\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"hidden_size\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"intermediate_size\"\u001b[0m: \u001b[1;36m3072\u001b[0m,\n",
       "  \u001b[32m\"layer_norm_eps\"\u001b[0m: \u001b[1;36m1e-12\u001b[0m,\n",
       "  \u001b[32m\"max_position_embeddings\"\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"bert\"\u001b[0m,\n",
       "  \u001b[32m\"num_attention_heads\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"num_hidden_layers\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"pad_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"position_embedding_type\"\u001b[0m: \u001b[32m\"absolute\"\u001b[0m,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.25.1\"\u001b[0m,\n",
       "  \u001b[32m\"type_vocab_size\"\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "  \u001b[32m\"use_cache\"\u001b[0m: true,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m30522\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e475145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a74e72d4d942d9a42e5376e645ee92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85162243cf3142218d87fa3278301321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Continuing from the above, we could retrain but that's super costly\n",
    "# Let's reuse by loading saved checkpoints\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Loading checkpoints should not interfere with the rest of the pipeline, assuming the architecture remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccdbbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/n/fs/nlp-jy1682/.cache/huggingface/misc/\")\n",
    "# Saves `config.json` and `pytorch_mode.bin` files to specified folder\n",
    "# * `pytorch_model.bin`: state dictionary (contains all model weights)\n",
    "# * `config.json: Save model locally (attributes of model arch. + metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20cd237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BaseModelOutputWithPoolingAndCrossAttentions</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">last_hidden_state</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.4496e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8276e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7797e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.4032e-02</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.9394e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.4770e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4943e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.4093e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.1772e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.1917e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2992e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.1172e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3668e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2518e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4502e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.6914e-02</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8224e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.5566e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1789e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6738e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8187e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4671e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0441e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.1962e-03</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.6436e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2464e-02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0258e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.0111e-02</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2451e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.0996e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.1866e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.8725e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1740e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.4012e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4553e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.7545e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3223e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.3271e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4876e-02</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.5268e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2172e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.1101e-04</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2523e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5754e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.1320e-02</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.7840e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0526e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.6255e-01</span><span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4042e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4718e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2110e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.6062e-02</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3564e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8262e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.5701e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.2787e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4968e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.5920e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0175e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3275e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0160e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5783e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.8974e-03</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.8850e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.1307e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.9732e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0175e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.4387e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.8147e-01</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.2109e-01</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0925e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.8456e-02</span><span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NativeLayerNormBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">pooler_output</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6856</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5262</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6112</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9971</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6055</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4997</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9998</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9999</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6753</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9769</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.7702</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5447</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9999</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4655</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9894</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">TanhBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hidden_states</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">past_key_values</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">cross_attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mBaseModelOutputWithPoolingAndCrossAttentions\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mlast_hidden_state\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m4.4496e-01\u001b[0m,  \u001b[1;36m4.8276e-01\u001b[0m,  \u001b[1;36m2.7797e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-5.4032e-02\u001b[0m,\n",
       "           \u001b[1;36m3.9394e-01\u001b[0m, \u001b[1;36m-9.4770e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m2.4943e-01\u001b[0m, \u001b[1;36m-4.4093e-01\u001b[0m,  \u001b[1;36m8.1772e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-3.1917e-01\u001b[0m,\n",
       "           \u001b[1;36m2.2992e-01\u001b[0m, \u001b[1;36m-4.1172e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m1.3668e-01\u001b[0m,  \u001b[1;36m2.2518e-01\u001b[0m,  \u001b[1;36m1.4502e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-4.6914e-02\u001b[0m,\n",
       "           \u001b[1;36m2.8224e-01\u001b[0m,  \u001b[1;36m7.5566e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m1.1789e+00\u001b[0m,  \u001b[1;36m1.6738e-01\u001b[0m, \u001b[1;36m-1.8187e-01\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m2.4671e-01\u001b[0m,\n",
       "           \u001b[1;36m1.0441e+00\u001b[0m, \u001b[1;36m-6.1962e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m3.6436e-01\u001b[0m,  \u001b[1;36m3.2464e-02\u001b[0m,  \u001b[1;36m2.0258e-01\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m6.0111e-02\u001b[0m,\n",
       "           \u001b[1;36m3.2451e-01\u001b[0m, \u001b[1;36m-2.0996e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m7.1866e-01\u001b[0m, \u001b[1;36m-4.8725e-01\u001b[0m,  \u001b[1;36m5.1740e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-4.4012e-01\u001b[0m,\n",
       "           \u001b[1;36m1.4553e-01\u001b[0m, \u001b[1;36m-3.7545e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m3.3223e-01\u001b[0m, \u001b[1;36m-2.3271e-01\u001b[0m,  \u001b[1;36m9.4876e-02\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-2.5268e-01\u001b[0m,\n",
       "           \u001b[1;36m3.2172e-01\u001b[0m,  \u001b[1;36m8.1101e-04\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m1.2523e+00\u001b[0m,  \u001b[1;36m3.5754e-01\u001b[0m, \u001b[1;36m-5.1320e-02\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-3.7840e-01\u001b[0m,\n",
       "           \u001b[1;36m1.0526e+00\u001b[0m, \u001b[1;36m-5.6255e-01\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2.4042e-01\u001b[0m,  \u001b[1;36m1.4718e-01\u001b[0m,  \u001b[1;36m1.2110e-01\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m7.6062e-02\u001b[0m,\n",
       "           \u001b[1;36m3.3564e-01\u001b[0m,  \u001b[1;36m2.8262e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m6.5701e-01\u001b[0m, \u001b[1;36m-3.2787e-01\u001b[0m,  \u001b[1;36m2.4968e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-2.5920e-01\u001b[0m,\n",
       "           \u001b[1;36m2.0175e-01\u001b[0m,  \u001b[1;36m3.3275e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m2.0160e-01\u001b[0m,  \u001b[1;36m1.5783e-01\u001b[0m,  \u001b[1;36m9.8974e-03\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-3.8850e-01\u001b[0m,\n",
       "           \u001b[1;36m4.1307e-01\u001b[0m,  \u001b[1;36m3.9732e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m1.0175e+00\u001b[0m,  \u001b[1;36m6.4387e-01\u001b[0m, \u001b[1;36m-7.8147e-01\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-4.2109e-01\u001b[0m,\n",
       "           \u001b[1;36m1.0925e+00\u001b[0m, \u001b[1;36m-4.8456e-02\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNativeLayerNormBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mpooler_output\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.6856\u001b[0m,  \u001b[1;36m0.5262\u001b[0m,  \u001b[1;36m1.0000\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m-0.6112\u001b[0m,  \u001b[1;36m0.9971\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.6055\u001b[0m,  \u001b[1;36m0.4997\u001b[0m,  \u001b[1;36m0.9998\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.9999\u001b[0m, \u001b[1;36m-0.6753\u001b[0m,  \u001b[1;36m0.9769\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-0.7702\u001b[0m,  \u001b[1;36m0.5447\u001b[0m,  \u001b[1;36m0.9999\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m1.0000\u001b[0m, \u001b[1;36m-0.4655\u001b[0m,  \u001b[1;36m0.9894\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mTanhBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mhidden_states\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpast_key_values\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mattentions\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mcross_attentions\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "# - Models can only process numbers, so we must tokenize first\n",
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]\n",
    "model_inputs = torch.tensor(encoded_sequences)\n",
    "output = model(model_inputs)\n",
    "print(output) # Outputs hidden state repr. (since this is BERT model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e6d2a",
   "metadata": {},
   "source": [
    "### Intro to `Tokenizer`<a class=\"anchor\" id=\"tokenizer-intro\"></a>\n",
    "Encoding: Translate text to numbers\n",
    "1. Tokenization: split text into words\n",
    "2. Conversion to input IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5617f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9608d76dafb24c27b31e5737700ea681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45802c75a253473e94593113842c9366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\") # Same checkpoint can be used for BERT Model, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8129ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e390664ba404688b7d9ebfcc1757444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternative\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f83eb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7993</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13809</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23763</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2443</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3014</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'token_type_ids'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'input_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m7993\u001b[0m, \u001b[1;36m170\u001b[0m, \u001b[1;36m13809\u001b[0m, \u001b[1;36m23763\u001b[0m, \u001b[1;36m2443\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m3014\u001b[0m, \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'token_type_ids'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'attention_mask'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tokenizer(\"Using a Transformer network is simple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ab1dacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Using'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Trans'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'##former'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'network'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simple'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'Using'\u001b[0m, \u001b[32m'a'\u001b[0m, \u001b[32m'Trans'\u001b[0m, \u001b[32m'##former'\u001b[0m, \u001b[32m'network'\u001b[0m, \u001b[32m'is'\u001b[0m, \u001b[32m'simple'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"Using a Transformer network is simple\")\n",
    "print(tokens) # Subword tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9870724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7993</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13809</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23763</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2443</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3014</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m7993\u001b[0m, \u001b[1;36m170\u001b[0m, \u001b[1;36m13809\u001b[0m, \u001b[1;36m23763\u001b[0m, \u001b[1;36m2443\u001b[0m, \u001b[1;36m1110\u001b[0m, \u001b[1;36m3014\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokens to input IDs\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98e65b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using a Transformer network is simple\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using a Transformer network is simple\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_string = tokenizer.decode(ids)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db987c28",
   "metadata": {},
   "source": [
    "### Towards Multiple Sentences<a class=\"anchor\" id=\"multiple-sentences\"></a>\n",
    "* How to handle multiple sequences (of different lengths)?\n",
    "* Are vocab indices the only inputs that allow a model to work well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bf76ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input IDs: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2310</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2042</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12172</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2607</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2878</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2166</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input IDs: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1045\u001b[0m,  \u001b[1;36m1005\u001b[0m,  \u001b[1;36m2310\u001b[0m,  \u001b[1;36m2042\u001b[0m,  \u001b[1;36m3403\u001b[0m,  \u001b[1;36m2005\u001b[0m,  \u001b[1;36m1037\u001b[0m, \u001b[1;36m17662\u001b[0m, \u001b[1;36m12172\u001b[0m,  \u001b[1;36m2607\u001b[0m,\n",
       "          \u001b[1;36m2026\u001b[0m,  \u001b[1;36m2878\u001b[0m,  \u001b[1;36m2166\u001b[0m,  \u001b[1;36m1012\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logits: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.7276</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8789</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logits: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-2.7276\u001b[0m,  \u001b[1;36m2.8789\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - Models expect a batch of inputs -\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load Tokenizer, Model\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "# Sentence -> Tokens -> IDs\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# Pass to model\n",
    "input_ids = torch.tensor([ids])\n",
    "print(\"Input IDs:\", input_ids)\n",
    "output = model(input_ids)\n",
    "print(\"Logits:\", output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "369960f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5694</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3895</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.5694\u001b[0m, \u001b[1;36m-1.3895\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5803</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4125</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.5803\u001b[0m, \u001b[1;36m-0.4125\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5694</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3895</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3374</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.2163</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.5694\u001b[0m, \u001b[1;36m-1.3895\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.3374\u001b[0m, \u001b[1;36m-1.2163\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - Padding Inputs w/ Different Lengths -\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence1_ids = [[200, 200, 200]]\n",
    "sequence2_ids = [[200, 200]]\n",
    "batched_ids = [\n",
    "    [200, 200, 200],\n",
    "    [200, 200, tokenizer.pad_token_id]\n",
    "]\n",
    "\n",
    "print(model(torch.tensor(sequence1_ids)).logits)\n",
    "print(model(torch.tensor(sequence2_ids)).logits)\n",
    "print(model(torch.tensor(batched_ids)).logits)\n",
    "\n",
    "# The representations for the second sentence are different in seq2_ids and batched_ids\n",
    "# This is because the representations are contextualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e53b2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5694</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3895</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5803</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4125</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.5694\u001b[0m, \u001b[1;36m-1.3895\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m0.5803\u001b[0m, \u001b[1;36m-0.4125\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To get the same representation, the attention layers should be asked to ignore padding tokens\n",
    "attention_mask = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 0]\n",
    "]\n",
    "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
    "print(outputs.logits) # Second sentence repr. is same as one when seq2_ids is passed in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
